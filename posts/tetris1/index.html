<!DOCTYPE html>
<html lang="es" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Aprendizaje automático en Tetris – Parte 1 | Joan — Projects —</title>
<meta name="keywords" content="">
<meta name="description" content="Introducción
Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.
A lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.
Tetris: el juego sencillo que desafía al aprendizaje automático
En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.
Pero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.
Sí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.">
<meta name="author" content="Joan">
<link rel="canonical" href="https://joan-projects.github.io/posts/tetris1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://joan-projects.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://joan-projects.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://joan-projects.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://joan-projects.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://joan-projects.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="es" href="https://joan-projects.github.io/posts/tetris1/">
<link rel="alternate" hreflang="en" href="https://joan-projects.github.io/en/posts/tetris1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" crossorigin="anonymous">
	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" crossorigin="anonymous"></script>
	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
	<style>
	   
	  .list .post-entry { 
		display: flex;             
		flex-direction: column;    
	  }
	  .list .post-entry .entry-header { order: 0; }    
	  .list .post-entry .entry-cover  { 
		order: 1;                  
		margin-top: .5rem; 
	  }
	</style>
<meta property="og:url" content="https://joan-projects.github.io/posts/tetris1/">
  <meta property="og:site_name" content="Joan — Projects —">
  <meta property="og:title" content="Aprendizaje automático en Tetris – Parte 1">
  <meta property="og:description" content="Introducción Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.
A lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.
Tetris: el juego sencillo que desafía al aprendizaje automático En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.
Pero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.
Sí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.">
  <meta property="og:locale" content="es-es">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-10-22T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-10-22T00:00:00+00:00">
    <meta property="og:image" content="https://joan-projects.github.io/img/Tetris1.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://joan-projects.github.io/img/Tetris1.png">
<meta name="twitter:title" content="Aprendizaje automático en Tetris – Parte 1">
<meta name="twitter:description" content="Introducción
Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.
A lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.
Tetris: el juego sencillo que desafía al aprendizaje automático
En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.
Pero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.
Sí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://joan-projects.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Aprendizaje automático en Tetris – Parte 1",
      "item": "https://joan-projects.github.io/posts/tetris1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Aprendizaje automático en Tetris – Parte 1",
  "name": "Aprendizaje automático en Tetris – Parte 1",
  "description": "Introducción Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.\nA lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.\nTetris: el juego sencillo que desafía al aprendizaje automático En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.\nPero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.\nSí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.\n",
  "keywords": [
    
  ],
  "articleBody": "Introducción Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.\nA lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.\nTetris: el juego sencillo que desafía al aprendizaje automático En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.\nPero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.\nSí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.\nVamos a ver por qué.\nEl número abrumador de posibilidades Para entender la magnitud del reto, basta comparar la cantidad de situaciones posibles en las que un jugador se puede encontrar en cada juego.\nEn Ajedrez, el número de configuraciones posibles del tablero ronda las 4,82 × 10⁴⁴. En Go, se dispara hasta las 2,08 × 10¹⁷⁰.\nEn comparación, Tetris juega en otra liga.\nUn tablero de Tetris de 20 filas por 10 columnas ya ofrece $2^{20\\times10}$ configuraciones posibles, pero eso es solo el principio.\nSi añadimos el factor de la bolsa aleatoria de piezas, y acotamos a una partida corta de unas 200 piezas (aproximadamente un minuto de juego), el número total de posibilidades escala a lo inconcebible:\n(1,37 × 10³⁷¹) × 2²⁰⁰ ≈ 2,2 × 10⁴³¹\nEn otras palabras, el espacio de estados de Tetris es astronómicamente más grande que el de cualquier otro juego clásico.\nTetris no es determinista: El caos de la aleatoriedad Y aún así, el tamaño del espacio de estados no es el mayor problema.\nLa verdadera dificultad radica en que Tetris no es un juego determinista.\nEn Ajedrez o Go, una jugada concreta siempre produce el mismo resultado. Las reglas son fijas y las consecuencias, previsibles.\nEn Tetris, en cambio, una decisión puede ser excelente o desastrosa dependiendo de qué pieza venga después.\nEl contexto cambia constantemente y el entorno es altamente inestable.\nEsto significa que la evaluación de una posición no puede depender solo del tablero actual: el futuro inmediato —impredecible por naturaleza— cambia el valor de cada acción.\nComo consecuencia, el famoso método MCTS (Monte Carlo Tree Search), que fue la piedra angular de AlphaZero y AlphaGo, resulta ineficaz para Tetris. Su estructura depende de escenarios deterministas y con resultados repetibles, justo lo contrario del caos tetrisiano.\nRecompensa, número de acciones y planificación El contraste se amplía cuando miramos la dinámica de decisiones:\nEn Ajedrez, un jugador toma unas 40 decisiones por partida. En Go, alrededor de 100. En Tetris, en cambio, el número de acciones es potencialmente infinito. Y mientras que en Ajedrez o Go la recompensa final es clara —victoria, empate o derrota—, en Tetris la recompensa puede definirse como una puntuación… pero sin un límite superior conocido.\nEsto complica enormemente la función de recompensa que una IA debe aprender.\nUna IA puede hacer una buena partida, pero ¿cómo sabe si su puntuación es “buena” o “excelente”?\nEsta falta de referencia complica el diseño de la función de recompensa, un elemento crucial en el aprendizaje por refuerzo.\nEl problema de la obtención de datos Para que una inteligencia artificial aprenda a jugar Tetris de verdad, no basta con mostrarle unas cuantas partidas: tiene que jugar miles, millones, incluso cientos de millones de veces.\nSolo así puede empezar a entender los patrones del juego y, poco a poco, descubrir por sí misma las estrategias más efectivas.\nPor suerte, los ordenadores juegan infinitamente más rápido que los humanos. Mientras una persona puede jugar unas pocas partidas en una hora, un agente de IA puede disputar millones de partidas en el mismo tiempo, aprendiendo de cada error y cada acierto.\nLo fundamental en este proceso es registrar lo que ocurre en cada momento: qué situación ve el agente, qué acción toma y qué resultado obtiene.\nA cada uno de estos registros lo llamamos una transición.\nCada transición es, en esencia, una pequeña lección que la IA guarda en su memoria para aprender cómo actuar la próxima vez que se enfrente a algo parecido.\nTetris frente a Ajedrez y Go En Ajedrez, una transición es muy rápida de calcular: en la mayoría de casos solo necesitamos verificar si la jugada es legal o no, por contra, en Tetris, no solo eso, sino que es necesario calcular cómo esa jugada afecta al tablero y construir la nueva bolsa de piezas.\nPara ser más precisos, realizar una transición en Ajedrez puede ser cientos de veces más rápido que hacerlo en Tetris.\nPor tanto, el tiempo total para obtener datos de entrenamiento es mucho mayor.\nEn cambio, si comparamos con Go, el tiempo por transición es similar.\nSin embargo —y aquí viene la trampa— la velocidad de simulación no lo es todo.\nAunque los ordenadores parezcan capaces de jugar a velocidades inimaginables, no son suficientes los recursos de un ordenador doméstico para entrenar una IA compleja de este tipo.\nEl problema no está solo en la potencia de cálculo, sino en el tiempo que lleva obtener datos realmente útiles.\nPor qué el tiempo de obtención de datos importa En juegos como el Ajedrez o el Go, las consecuencias suelen hacerse evidentes bastante rápido, normalmente en la siguiente transición. En cambio, en Tetris, cuando se juega a un nivel avanzado, pueden notarse incluso más de diez transiciones después. Es por eso que una mala jugada puede parecer buena durante varias iteraciones, hasta que sus consecuencias aparecen más tarde.\nEsto obliga al agente a mantener un “sentido del futuro”: una memoria que relacione decisiones pasadas con resultados tardíos. Pero ¿cómo hacerlo en Tetris? No sabemos qué fichas van a llegar, por lo que lo que el jugador ve en un momento dado no es facilmente evaluable.\nY si además queremos que el sistema simule distintas alternativas antes de decidirse —como hace el algoritmo MCTS (Monte Carlo Tree Search)—, el tiempo de cómputo crece exponencialmente.\nPuedes imaginarlo como un jugador de ajedrez que analiza mentalmente tres, cuatro o cinco jugadas por adelantado antes de mover una pieza.\nAhora imagina que debe hacerlo millones de veces por segundo: ahí está la dificultad.\nAumentación de datos: multiplicar la experiencia sin jugar más Una técnica muy poderosa para acelerar el aprendizaje es la aumentación de datos (data augmentation).\nConsiste en crear nuevos ejemplos a partir de los que ya tenemos, modificándolos de forma que sigan siendo válidos, pero aporten variedad al entrenamiento.\nUn ejemplo clásico viene del Ajedrez:\nimagina un final de partida con dos torres intentando dar jaque mate a un rey.\nSi el rey enemigo está en la esquina superior derecha del tablero y logramos el mate en tres movimientos, esa misma secuencia es exactamente equivalente por simetría si el rey está en cualquiera de las otras tres esquinas.\nEs decir, de un solo dato obtenemos cuatro, casi gratis.\nEn Ajedrez, casi todas las posiciones pueden duplicarse (×2), y la mayoría cuadruplicarse (×4). En Go, gracias a sus simetrías y rotaciones, podemos hacer un ×8 de cada dato. En Tetris, sin embargo, la situación es menos favorable: el tablero tiene una única orientación posible (la gravedad actúa siempre hacia abajo), por lo que solo podemos duplicar (×2) los datos disponibles. Esto significa que Tetris parte con un hándicap adicional: no solo necesita más datos, sino que además puede generarlos más lentamente y aprovechar menos la aumentación.\nPor qué la aumentación es esencial La aumentación de datos no solo multiplica la cantidad de información disponible, sino que enseña al sistema a reconocer patrones fundamentales.\nAl ver situaciones equivalentes desde distintas perspectivas, la IA aprende a generalizar mejor, a entender qué características del tablero son realmente importantes y cuáles son circunstanciales.\nEs como enseñarle a un perro a reconocer un ladrón, si solo ha visto uno vestido de negro, pensará que todos los ladrones van de negro.\nPero si ha visto ladrones con chaquetas, gorros o camisetas de colores, aprenderá que lo importante no es el color de la ropa, sino el hecho de que se llevan objetos de la casa del dueño.\nHeurística vs. aprendizaje automatizado: dos caminos distintos Antes de la era del aprendizaje automático, al igual que pasó en Ajedrez, se consiguió en Tetris alcanzaron resultados sorprendentes usando métodos heurísticos.\nLa idea era sencilla: simular todas las posiciones posibles tras colocar una o varias piezas y evaluar cada tablero con una función matemática diseñada por humanos.\nPor ejemplo, una heurística típica penaliza los huecos, premia las líneas completas y busca minimizar la altura media de las columnas.\nEl programa genera cientos o miles de tableros posibles y escoge el movimiento que produzca el valor más alto según esa función.\nEl problema es que una heurística no “piensa” realmente.\nSolo ejecuta una fórmula fija, escrita por un desarrollador.\nToda la “inteligencia” reside en la función de evaluación, no en el sistema.\nEsto significa que el programa nunca aprenderá algo nuevo: si el creador no conoce la mejor estrategia, la IA tampoco la descubrirá.\nEl aprendizaje automatizado, en cambio, representa un salto cualitativo.\nNos permite enfrentarnos a problemas en los que la estrategia óptima es desconocida, porque el propio sistema la descubrirá durante el entrenamiento.\nMediante miles de partidas, ensayo y error, y ajustes de valoración, la IA aprende por sí sola qué patrones conducen al éxito, incluso en entornos tan caóticos e impredecibles como Tetris.\nNo necesita que le indiquemos qué características hacen buena una posición: las termina por deducir.\nEsa capacidad de generar conocimiento sin intervención humana directa es lo que convierte al aprendizaje automático —y especialmente al aprendizaje por refuerzo— en una herramienta revolucionaria.\nAdemás, el enfoque heurístico no puede planificar estrategias a varias jugadas de profundidad.\nEsto se debe a que el número de configuraciones crece de forma exponencial con cada pieza añadida (en Tetris, del orden de $162^{n}$).\nSi el algoritmo intentara prever el resultado de, digamos, cinco piezas futuras, debería explorar $162^{5}≈10^{11}$ —una tarea imposible en tiempo real.\nPor tanto, la heurística vive en el presente: solo puede optimizar el movimiento inmediato.\nEl aprendizaje automatizado, en cambio, puede anticipar el futuro al incorporar la recompensa esperada a largo plazo en su proceso de entrenamiento.\nEsto le permite desarrollar estrategias sostenibles, que no solo buscan la ganancia inmediata (como limpiar una línea), sino mantener el tablero estable y adaptable para las próximas piezas.\nCierre Ahora que hemos establecido los principales retos que enfrenta un agente de aprendizaje automático en Tetris, en los próximos capítulos exploraremos paso a paso cómo evolucionó mi sistema hasta llegar al ansiado objetivo:\nuna IA capaz de jugar Tetris al nivel más alto posible.\n",
  "wordCount" : "1852",
  "inLanguage": "es",
  "image":"https://joan-projects.github.io/img/Tetris1.png","datePublished": "2025-10-22T00:00:00Z",
  "dateModified": "2025-10-22T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Joan"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://joan-projects.github.io/posts/tetris1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Joan — Projects —",
    "logo": {
      "@type": "ImageObject",
      "url": "https://joan-projects.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://joan-projects.github.io/" accesskey="h" title="Joan — Projects — (Alt + H)">Joan — Projects —</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                    <ul class="lang-switch"><li>|</li>
                        <li>
                            <a href="https://joan-projects.github.io/en/" title="English"
                                aria-label="English">En</a>
                        </li>
                    </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://joan-projects.github.io/" title="Inicio">
                    <span>Inicio</span>
                </a>
            </li>
            <li>
                <a href="https://joan-projects.github.io/posts/" title="Artículos">
                    <span>Artículos</span>
                </a>
            </li>
            <li>
                <a href="https://joan-projects.github.io/contacto/" title="Contacto">
                    <span>Contacto</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Aprendizaje automático en Tetris – Parte 1
    </h1>
    <div class="post-meta"><span title='2025-10-22 00:00:00 +0000 UTC'>22 de octubre de 2025</span>&nbsp;·&nbsp;<span>9 min</span>&nbsp;·&nbsp;<span>Joan</span>&nbsp;|&nbsp;<span>Traducciones:</span>
<ul class="i18n_list">
    <li>
        <a href="https://joan-projects.github.io/en/posts/tetris1/">En</a>
    </li>
</ul>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" src="https://joan-projects.github.io/img/Tetris1.png" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Tabla de Contenidos</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introducci%c3%b3n" aria-label="Introducción">Introducción</a></li>
                <li>
                    <a href="#tetris-el-juego-sencillo-que-desaf%c3%ada-al-aprendizaje-autom%c3%a1tico" aria-label="Tetris: el juego sencillo que desafía al aprendizaje automático">Tetris: el juego sencillo que desafía al aprendizaje automático</a></li>
                <li>
                    <a href="#el-n%c3%bamero-abrumador-de-posibilidades" aria-label="El número abrumador de posibilidades">El número abrumador de posibilidades</a></li>
                <li>
                    <a href="#tetris-no-es-determinista-el-caos-de-la-aleatoriedad" aria-label="Tetris no es determinista: El caos de la aleatoriedad">Tetris no es determinista: El caos de la aleatoriedad</a></li>
                <li>
                    <a href="#recompensa-n%c3%bamero-de-acciones-y-planificaci%c3%b3n" aria-label="Recompensa, número de acciones y planificación">Recompensa, número de acciones y planificación</a></li>
                <li>
                    <a href="#el-problema-de-la-obtenci%c3%b3n-de-datos" aria-label="El problema de la obtención de datos">El problema de la obtención de datos</a></li>
                <li>
                    <a href="#tetris-frente-a-ajedrez-y-go" aria-label="Tetris frente a Ajedrez y Go">Tetris frente a Ajedrez y Go</a></li>
                <li>
                    <a href="#por-qu%c3%a9-el-tiempo-de-obtenci%c3%b3n-de-datos-importa" aria-label="Por qué el tiempo de obtención de datos importa">Por qué el tiempo de obtención de datos importa</a></li>
                <li>
                    <a href="#aumentaci%c3%b3n-de-datos-multiplicar-la-experiencia-sin-jugar-m%c3%a1s" aria-label="Aumentación de datos: multiplicar la experiencia sin jugar más">Aumentación de datos: multiplicar la experiencia sin jugar más</a></li>
                <li>
                    <a href="#por-qu%c3%a9-la-aumentaci%c3%b3n-es-esencial" aria-label="Por qué la aumentación es esencial">Por qué la aumentación es esencial</a></li>
                <li>
                    <a href="#heur%c3%adstica-vs-aprendizaje-automatizado-dos-caminos-distintos" aria-label="Heurística vs. aprendizaje automatizado: dos caminos distintos">Heurística vs. aprendizaje automatizado: dos caminos distintos</a></li>
                <li>
                    <a href="#cierre" aria-label="Cierre">Cierre</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introducción">Introducción<a hidden class="anchor" aria-hidden="true" href="#introducción">#</a></h2>
<p>Comienza aquí una serie de artículos donde te contaré mi viaje para desarrollar una inteligencia artificial capaz de jugar Tetris al máximo nivel, en tiempo real, dentro del entorno tetr.io — El mismo donde compiten hoy los jugadores profesionales.<br>
A lo largo de esta serie compartiré y describiré los hitos conseguidos hasta la publicación del repositorio final con la IA totalmente entrenada.</p>
<h2 id="tetris-el-juego-sencillo-que-desafía-al-aprendizaje-automático">Tetris: el juego sencillo que desafía al aprendizaje automático<a hidden class="anchor" aria-hidden="true" href="#tetris-el-juego-sencillo-que-desafía-al-aprendizaje-automático">#</a></h2>
<p>En la historia del aprendizaje automático, hay momentos canónicos que son legendarios: AlphaGo y AlphaZero alcanzaron un rendimiento sobrehumano en Go y Ajedrez, demostrando que una inteligencia artificial puede aprender por sí sola, simplemente jugando contra sí misma, sin ninguna ayuda humana, hasta superar a los mejores jugadores del mundo en juegos donde la estrategia lo es todo.<br>
Pero hay un juego que, aunque parece más simple, es un reto todavía mayor para una IA: Tetris.<br>
Sí, ese juego de piezas que caen sin descanso puede ser un auténtico infierno para los sistemas de aprendizaje automático cuando se intenta alcanzar un nivel comparable —o superior— al de un jugador experimentado, y mucho más aún al de un profesional.</p>
<p>Vamos a ver por qué.</p>
<h2 id="el-número-abrumador-de-posibilidades">El número abrumador de posibilidades<a hidden class="anchor" aria-hidden="true" href="#el-número-abrumador-de-posibilidades">#</a></h2>
<p>Para entender la magnitud del reto, basta comparar la cantidad de situaciones posibles en las que un jugador se puede encontrar en cada juego.<br>
En Ajedrez, el número de configuraciones posibles del tablero ronda las 4,82 × 10⁴⁴. En Go, se dispara hasta las 2,08 × 10¹⁷⁰.<br>
En comparación, Tetris juega en otra liga.<br>
Un tablero de Tetris de 20 filas por 10 columnas ya ofrece $2^{20\times10}$
configuraciones posibles, pero eso es solo el principio.<br>
Si añadimos el factor de la bolsa aleatoria de piezas, y acotamos a una partida corta de unas 200 piezas (aproximadamente un minuto de juego), el número total de posibilidades escala a lo inconcebible:</p>
<p>(1,37 × 10³⁷¹) × 2²⁰⁰ ≈ 2,2 × 10⁴³¹</p>
<p>En otras palabras, el espacio de estados de Tetris es astronómicamente más grande que el de cualquier otro juego clásico.</p>
<h2 id="tetris-no-es-determinista-el-caos-de-la-aleatoriedad">Tetris no es determinista: El caos de la aleatoriedad<a hidden class="anchor" aria-hidden="true" href="#tetris-no-es-determinista-el-caos-de-la-aleatoriedad">#</a></h2>
<p>Y aún así, el tamaño del espacio de estados no es el mayor problema.<br>
La verdadera dificultad radica en que Tetris no es un juego determinista.<br>
En Ajedrez o Go, una jugada concreta siempre produce el mismo resultado. Las reglas son fijas y las consecuencias, previsibles.<br>
En Tetris, en cambio, una decisión puede ser excelente o desastrosa dependiendo de qué pieza venga después.<br>
El contexto cambia constantemente y el entorno es altamente inestable.<br>
Esto significa que la evaluación de una posición no puede depender solo del tablero actual: el futuro inmediato —impredecible por naturaleza— cambia el valor de cada acción.<br>
Como consecuencia, el famoso método MCTS (Monte Carlo Tree Search), que fue la piedra angular de AlphaZero y AlphaGo, resulta ineficaz para Tetris. Su estructura depende de escenarios deterministas y con resultados repetibles, justo lo contrario del caos tetrisiano.</p>
<h2 id="recompensa-número-de-acciones-y-planificación">Recompensa, número de acciones y planificación<a hidden class="anchor" aria-hidden="true" href="#recompensa-número-de-acciones-y-planificación">#</a></h2>
<p>El contraste se amplía cuando miramos la dinámica de decisiones:</p>
<ul>
<li>En Ajedrez, un jugador toma unas 40 decisiones por partida.</li>
<li>En Go, alrededor de 100.</li>
<li>En Tetris, en cambio, el número de acciones es potencialmente infinito.</li>
</ul>
<p>Y mientras que en Ajedrez o Go la recompensa final es clara —victoria, empate o derrota—, en Tetris la recompensa puede definirse como una puntuación… pero sin un límite superior conocido.<br>
Esto complica enormemente la función de recompensa que una IA debe aprender.<br>
Una IA puede hacer una buena partida, pero ¿cómo sabe si su puntuación es “buena” o “excelente”?<br>
Esta falta de referencia complica el diseño de la función de recompensa, un elemento crucial en el aprendizaje por refuerzo.</p>
<h2 id="el-problema-de-la-obtención-de-datos">El problema de la obtención de datos<a hidden class="anchor" aria-hidden="true" href="#el-problema-de-la-obtención-de-datos">#</a></h2>
<p>Para que una inteligencia artificial aprenda a jugar Tetris de verdad, no basta con mostrarle unas cuantas partidas: tiene que jugar miles, millones, incluso cientos de millones de veces.<br>
Solo así puede empezar a entender los patrones del juego y, poco a poco, descubrir por sí misma las estrategias más efectivas.<br>
Por suerte, los ordenadores juegan infinitamente más rápido que los humanos. Mientras una persona puede jugar unas pocas partidas en una hora, un agente de IA puede disputar millones de partidas en el mismo tiempo, aprendiendo de cada error y cada acierto.<br>
Lo fundamental en este proceso es registrar lo que ocurre en cada momento: qué situación ve el agente, qué acción toma y qué resultado obtiene.<br>
A cada uno de estos registros lo llamamos una <strong>transición</strong>.<br>
Cada transición es, en esencia, una pequeña lección que la IA guarda en su memoria para aprender cómo actuar la próxima vez que se enfrente a algo parecido.</p>
<h2 id="tetris-frente-a-ajedrez-y-go">Tetris frente a Ajedrez y Go<a hidden class="anchor" aria-hidden="true" href="#tetris-frente-a-ajedrez-y-go">#</a></h2>
<p>En Ajedrez, una transición es muy rápida de calcular: en la mayoría de casos solo necesitamos verificar si la jugada es legal o no, por contra, en Tetris, no solo eso, sino que es necesario calcular cómo esa jugada afecta al tablero y construir la nueva bolsa de piezas.<br>
Para ser más precisos, realizar una transición en Ajedrez puede ser cientos de veces más rápido que hacerlo en Tetris.<br>
Por tanto, el tiempo total para obtener datos de entrenamiento es mucho mayor.<br>
En cambio, si comparamos con Go, el tiempo por transición es similar.<br>
Sin embargo —y aquí viene la trampa— la velocidad de simulación no lo es todo.<br>
Aunque los ordenadores parezcan capaces de jugar a velocidades inimaginables, no son suficientes los recursos de un ordenador doméstico para entrenar una IA compleja de este tipo.<br>
El problema no está solo en la potencia de cálculo, sino en el tiempo que lleva obtener datos realmente útiles.</p>
<h2 id="por-qué-el-tiempo-de-obtención-de-datos-importa">Por qué el tiempo de obtención de datos importa<a hidden class="anchor" aria-hidden="true" href="#por-qué-el-tiempo-de-obtención-de-datos-importa">#</a></h2>
<p>En juegos como el Ajedrez o el Go, las consecuencias suelen hacerse evidentes bastante rápido, normalmente en la siguiente transición. En cambio, en Tetris, cuando se juega a un nivel avanzado, pueden notarse incluso más de diez transiciones después.
Es por eso que una mala jugada puede parecer buena durante varias iteraciones, hasta que sus consecuencias aparecen más tarde.<br>
Esto obliga al agente a mantener un “sentido del futuro”: una memoria que relacione decisiones pasadas con resultados tardíos.
Pero ¿cómo hacerlo en Tetris? No sabemos qué fichas van a llegar, por lo que lo que el jugador ve en un momento dado no es facilmente evaluable.<br>
Y si además queremos que el sistema simule distintas alternativas antes de decidirse —como hace el algoritmo MCTS (Monte Carlo Tree Search)—, el tiempo de cómputo crece exponencialmente.<br>
Puedes imaginarlo como un jugador de ajedrez que analiza mentalmente tres, cuatro o cinco jugadas por adelantado antes de mover una pieza.<br>
Ahora imagina que debe hacerlo millones de veces por segundo: ahí está la dificultad.</p>
<h2 id="aumentación-de-datos-multiplicar-la-experiencia-sin-jugar-más">Aumentación de datos: multiplicar la experiencia sin jugar más<a hidden class="anchor" aria-hidden="true" href="#aumentación-de-datos-multiplicar-la-experiencia-sin-jugar-más">#</a></h2>
<p>Una técnica muy poderosa para acelerar el aprendizaje es la <strong>aumentación de datos</strong> (<em>data augmentation</em>).<br>
Consiste en crear nuevos ejemplos a partir de los que ya tenemos, modificándolos de forma que sigan siendo válidos, pero aporten variedad al entrenamiento.</p>
<p>Un ejemplo clásico viene del Ajedrez:<br>
imagina un final de partida con dos torres intentando dar jaque mate a un rey.<br>
Si el rey enemigo está en la esquina superior derecha del tablero y logramos el mate en tres movimientos, esa misma secuencia es exactamente equivalente por simetría si el rey está en cualquiera de las otras tres esquinas.<br>
Es decir, de un solo dato obtenemos cuatro, casi gratis.</p>
<ul>
<li>En Ajedrez, casi todas las posiciones pueden duplicarse (×2), y la mayoría cuadruplicarse (×4).</li>
<li>En Go, gracias a sus simetrías y rotaciones, podemos hacer un ×8 de cada dato.</li>
<li>En Tetris, sin embargo, la situación es menos favorable: el tablero tiene una única orientación posible (la gravedad actúa siempre hacia abajo), por lo que solo podemos duplicar (×2) los datos disponibles.</li>
</ul>
<p>Esto significa que Tetris parte con un hándicap adicional: no solo necesita más datos, sino que además puede generarlos más lentamente y aprovechar menos la aumentación.</p>
<h2 id="por-qué-la-aumentación-es-esencial">Por qué la aumentación es esencial<a hidden class="anchor" aria-hidden="true" href="#por-qué-la-aumentación-es-esencial">#</a></h2>
<p>La aumentación de datos no solo multiplica la cantidad de información disponible, sino que enseña al sistema a reconocer patrones fundamentales.<br>
Al ver situaciones equivalentes desde distintas perspectivas, la IA aprende a generalizar mejor, a entender qué características del tablero son realmente importantes y cuáles son circunstanciales.<br>
Es como enseñarle a un perro a reconocer un ladrón, si solo ha visto uno vestido de negro, pensará que todos los ladrones van de negro.<br>
Pero si ha visto ladrones con chaquetas, gorros o camisetas de colores, aprenderá que lo importante no es el color de la ropa, sino el hecho de que se llevan objetos de la casa del dueño.</p>
<h2 id="heurística-vs-aprendizaje-automatizado-dos-caminos-distintos">Heurística vs. aprendizaje automatizado: dos caminos distintos<a hidden class="anchor" aria-hidden="true" href="#heurística-vs-aprendizaje-automatizado-dos-caminos-distintos">#</a></h2>
<p>Antes de la era del aprendizaje automático, al igual que pasó en Ajedrez, se consiguió en Tetris alcanzaron resultados sorprendentes usando métodos heurísticos.<br>
La idea era sencilla: simular todas las posiciones posibles tras colocar una o varias piezas y evaluar cada tablero con una función matemática diseñada por humanos.<br>
Por ejemplo, una heurística típica penaliza los huecos, premia las líneas completas y busca minimizar la altura media de las columnas.<br>
El programa genera cientos o miles de tableros posibles y escoge el movimiento que produzca el valor más alto según esa función.</p>
<p>El problema es que una heurística no “piensa” realmente.<br>
Solo ejecuta una fórmula fija, escrita por un desarrollador.<br>
Toda la “inteligencia” reside en la función de evaluación, no en el sistema.<br>
Esto significa que el programa nunca aprenderá algo nuevo: si el creador no conoce la mejor estrategia, la IA tampoco la descubrirá.</p>
<p>El aprendizaje automatizado, en cambio, representa un salto cualitativo.<br>
Nos permite enfrentarnos a problemas en los que la estrategia óptima es desconocida, porque el propio sistema la descubrirá durante el entrenamiento.<br>
Mediante miles de partidas, ensayo y error, y ajustes de valoración, la IA aprende por sí sola qué patrones conducen al éxito, incluso en entornos tan caóticos e impredecibles como Tetris.<br>
No necesita que le indiquemos qué características hacen buena una posición: las termina por deducir.<br>
Esa capacidad de generar conocimiento sin intervención humana directa es lo que convierte al aprendizaje automático —y especialmente al aprendizaje por refuerzo— en una herramienta revolucionaria.</p>
<p>Además, el enfoque heurístico no puede planificar estrategias a varias jugadas de profundidad.<br>
Esto se debe a que el número de configuraciones crece de forma exponencial con cada pieza añadida (en Tetris, del orden de $162^{n}$).<br>
Si el algoritmo intentara prever el resultado de, digamos, cinco piezas futuras, debería explorar $162^{5}≈10^{11}$ —una tarea imposible en tiempo real.<br>
Por tanto, la heurística vive en el presente: solo puede optimizar el movimiento inmediato.<br>
El aprendizaje automatizado, en cambio, puede anticipar el futuro al incorporar la recompensa esperada a largo plazo en su proceso de entrenamiento.<br>
Esto le permite desarrollar estrategias sostenibles, que no solo buscan la ganancia inmediata (como limpiar una línea), sino mantener el tablero estable y adaptable para las próximas piezas.</p>
<h2 id="cierre">Cierre<a hidden class="anchor" aria-hidden="true" href="#cierre">#</a></h2>
<p>Ahora que hemos establecido los principales retos que enfrenta un agente de aprendizaje automático en Tetris, en los próximos capítulos exploraremos paso a paso cómo evolucionó mi sistema hasta llegar al ansiado objetivo:<br>
una IA capaz de jugar Tetris al nivel más alto posible.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on x"
            href="https://x.com/intent/tweet/?text=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201&amp;url=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f&amp;title=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201&amp;summary=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201&amp;source=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f&title=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on whatsapp"
            href="https://api.whatsapp.com/send?text=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201%20-%20https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on telegram"
            href="https://telegram.me/share/url?text=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201&amp;url=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Aprendizaje automático en Tetris – Parte 1 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Aprendizaje%20autom%c3%a1tico%20en%20Tetris%20%e2%80%93%20Parte%201&u=https%3a%2f%2fjoan-projects.github.io%2fposts%2ftetris1%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://joan-projects.github.io/">Joan — Projects —</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>
<script>
  window.addEventListener("load", function () {
    if (window.renderMathInElement) {
      const root = document.querySelector("article, .post-content, main, body");
      renderMathInElement(root, {
        delimiters: [
          {left: "$$", right: "$$", display: true},
          {left: "$", right: "$", display: false},
          {left: "\\(", right: "\\)", display: false},
          {left: "\\[", right: "\\]", display: true}
        ],
        throwOnError: false
        
        
        
      });
    }
  });
</script>



<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
